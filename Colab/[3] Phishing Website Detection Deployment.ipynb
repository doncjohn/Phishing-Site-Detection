{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMDvtzoR7xwLjtWVoVFpDQ0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Installing Packages\n","!pip install python-whois\n","import pandas as pd\n","import re\n","import ipaddress\n","from urllib.parse import urlparse\n","import whois\n","import requests\n","from datetime import datetime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEwJSrWO30ZI","executionInfo":{"status":"ok","timestamp":1690292986169,"user_tz":-330,"elapsed":4602,"user":{"displayName":"Don C John","userId":"06394153183726699086"}},"outputId":"7ee063e5-ed73-4bc4-df3b-c5e2ac16b6a0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-whois\n","  Downloading python-whois-0.8.0.tar.gz (109 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/109.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from python-whois) (0.18.3)\n","Building wheels for collected packages: python-whois\n","  Building wheel for python-whois (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-whois: filename=python_whois-0.8.0-py3-none-any.whl size=103247 sha256=75c41424fb667389651db9be5ef3ddb318c94a6d4599f6c330313a57bb2688b7\n","  Stored in directory: /root/.cache/pip/wheels/10/f1/87/145023b9a206e2e948be6480c61ef3fd3dbb81ef11b6977782\n","Successfully built python-whois\n","Installing collected packages: python-whois\n","Successfully installed python-whois-0.8.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ReQZ9siVwXfC","executionInfo":{"status":"ok","timestamp":1690292986171,"user_tz":-330,"elapsed":15,"user":{"displayName":"Don C John","userId":"06394153183726699086"}}},"outputs":[],"source":["#Function to extract features from a URL\n","def extract_features_from_url(url):\n","    # Helper function to get the domain from a URL\n","    def get_domain(url):\n","        domain = urlparse(url).netloc\n","        if re.match(r\"^www.\", domain):\n","            domain = domain.replace(\"www.\", \"\")\n","        return domain\n","\n","    # Helper function to check for the presence of an IP address in the URL\n","    def having_ip(url):\n","        try:\n","            ipaddress.ip_address(url)\n","            ip = 1\n","        except:\n","            ip = 0\n","        return ip\n","\n","    # Helper function to check for the presence of '@' symbol in the URL\n","    def have_at_sign(url):\n","        if \"@\" in url:\n","            at = 1\n","        else:\n","            at = 0\n","        return at\n","\n","    # Helper function to compute the length of the URL\n","    def get_length(url):\n","        if len(url) < 54:\n","            length = 0\n","        else:\n","            length = 1\n","        return length\n","\n","    # Helper function to compute the depth of the URL\n","    def get_depth(url):\n","        s = urlparse(url).path.split('/')\n","        depth = 0\n","        for j in range(len(s)):\n","            if len(s[j]) != 0:\n","                depth = depth + 1\n","        return depth\n","\n","    # Helper function to check for the presence of \"//\" in the URL\n","    def redirection(url):\n","        pos = url.rfind('//')\n","        if pos > 6:\n","            if pos > 7:\n","                return 1\n","            else:\n","                return 0\n","        else:\n","            return 0\n","\n","    # Helper function to check for the presence of \"http/https\" in the domain part of the URL\n","    def http_domain(url):\n","        domain = urlparse(url).netloc\n","        if 'https' in domain:\n","            return 1\n","        else:\n","            return 0\n","\n","    # Helper function to check for the use of URL shortening services\n","    def tiny_url(url):\n","        shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n","                              r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n","                              r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n","                              r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n","                              r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n","                              r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n","                              r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n","                              r\"tr\\.im|link\\.zip\\.net\"\n","        match = re.search(shortening_services, url)\n","        if match:\n","            return 1\n","        else:\n","            return 0\n","\n","    # Helper function to check for the presence of '-' in the domain part of the URL\n","    def prefix_suffix(url):\n","        if '-' in urlparse(url).netloc:\n","            return 1  # phishing\n","        else:\n","            return 0  # legitimate\n","\n","    # Helper function to check for the availability of DNS records for the hostname\n","    def dns_record(domain_name):\n","        try:\n","            domain_info = whois.whois(domain_name)\n","            return 0\n","        except:\n","            return 1\n","\n","    # Helper function to check the web traffic of the URL\n","    def web_traffic(url):\n","        return 1  # Placeholder, you may implement the actual logic using web traffic data sources\n","\n","    # Helper function to compute the age of the domain\n","    def domain_age(domain_name):\n","        try:\n","            domain_info = whois.whois(domain_name)\n","            creation_date = domain_info.creation_date\n","            expiration_date = domain_info.expiration_date\n","            if (isinstance(creation_date, str) or isinstance(expiration_date, str)):\n","                try:\n","                    creation_date = datetime.strptime(str(creation_date), '%Y-%m-%d %H:%M:%S')\n","                    expiration_date = datetime.strptime(str(expiration_date), '%Y-%m-%d %H:%M:%S')\n","                except:\n","                    return 1\n","            if ((expiration_date is None) or (creation_date is None)):\n","                return 1\n","            elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n","                return 1\n","            else:\n","                age_of_domain = abs((expiration_date - creation_date).days)\n","                if ((age_of_domain / 30) < 6):\n","                    age = 1\n","                else:\n","                    age = 0\n","            return age\n","        except:\n","            return 1\n","\n","    # Helper function to compute the remaining domain time before expiration\n","    def domain_end(domain_name):\n","        try:\n","            domain_info = whois.whois(domain_name)\n","            expiration_date = domain_info.expiration_date\n","            if isinstance(expiration_date, str):\n","                try:\n","                    expiration_date = datetime.strptime(str(expiration_date), '%Y-%m-%d %H:%M:%S')\n","                except:\n","                    return 1\n","            if (expiration_date is None):\n","                return 1\n","            elif (type(expiration_date) is list):\n","                return 1\n","            else:\n","                today = datetime.now()\n","                end = abs((expiration_date - today).days)\n","                if ((end / 30) < 6):\n","                    end = 0\n","                else:\n","                    end = 1\n","            return end\n","        except:\n","            return 1\n","\n","    # Helper function to check for the presence of \"iframe\" tags in the webpage source code\n","    def iframe(response):\n","        if response == \"\":\n","            return 1\n","        else:\n","            if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n","                return 0\n","            else:\n","                return 1\n","\n","    # Helper function to check the effect of mouse over on the status bar\n","    def mouse_over(response):\n","        if response == \"\":\n","            return 1\n","        else:\n","            if re.findall(\"<script>.+onmouseover.+</script>\", response.text):\n","                return 1\n","            else:\n","                return 0\n","\n","    # Helper function to check the status of the right-click attribute\n","    def right_click(response):\n","        if response == \"\":\n","            return 1\n","        else:\n","            if re.findall(r\"event.button ?== ?2\", response.text):\n","                return 0\n","            else:\n","                return 1\n","\n","    # Helper function to check the number of forwardings in the URL\n","    def web_forwards(url):\n","        try:\n","            response = requests.get(url)\n","            if response.status_code == 200:\n","                return 0\n","            else:\n","                return 1\n","        except:\n","            return 1\n","\n","    # Extract features\n","    ip_present = having_ip(url)\n","    at_present = have_at_sign(url)\n","    url_len = get_length(url)\n","    url_depth = get_depth(url)\n","    redirection_present = redirection(url)\n","    https_in_domain = http_domain(url)\n","    tinyurl_present = tiny_url(url)\n","    prefix_suffix_present = prefix_suffix(url)\n","    dns_rec = dns_record(get_domain(url))\n","    web_traffic_status = web_traffic(url)\n","    domain_age_status = domain_age(get_domain(url))\n","    domain_end_status = domain_end(get_domain(url))\n","\n","    # As web_forwards function requires an actual request to the URL, we'll handle it separately\n","    try:\n","        response = requests.get(url)\n","        web_forwards_status = web_forwards(url)\n","    except:\n","        web_forwards_status = 1\n","\n","    # Create an array of the extracted features\n","    features_array = [ip_present, at_present, url_len, url_depth, redirection_present, https_in_domain, tinyurl_present,\n","                      prefix_suffix_present, dns_rec, web_traffic_status, domain_age_status, domain_end_status,\n","                      iframe(response), mouse_over(response), right_click(response), web_forwards_status]\n","\n","    return features_array"]},{"cell_type":"code","source":["#Extract Features from URL\n","test_url = \"https://colab.research.google.com/drive/129-DGfnDTW08yCKcTrpyK5XYWpzCoMO3\"\n","features = extract_features_from_url(test_url)\n","print(features)"],"metadata":{"id":"RM-bCJTD4Hcx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690292987459,"user_tz":-330,"elapsed":1300,"user":{"displayName":"Don C John","userId":"06394153183726699086"}},"outputId":"6c720bf0-dfe3-45dd-abb7-cab5124c97d8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n"]}]},{"cell_type":"code","source":["import pickle\n","\n","# Load the XGBoost model\n","loaded_model = pickle.load(open(\"XGBoostClassifier.pickle.dat\", \"rb\"))\n","\n","# Convert the preprocessed URL data to a DataFrame (assuming it's in the same format as the training data)\n","feature_names = [\n","    'Have_IP', 'Have_At', 'URL_Length', 'URL_Depth', 'Redirection', 'https_Domain', 'TinyURL', 'Prefix/Suffix',\n","    'DNS_Record', 'Web_Traffic', 'Domain_Age', 'Domain_End', 'iFrame', 'Mouse_Over', 'Right_Click', 'Web_Forwards'\n","]\n","url_df = pd.DataFrame([features], columns=feature_names)\n","\n","# Predict the label using the loaded XGBoost model\n","prediction = loaded_model.predict(url_df)\n","\n","# Print the prediction (1 for phishing, 0 for legitimate)\n","if prediction[0] == 1:\n","    print(\"Phishing URL\")\n","else:\n","    print(\"Legitimate URL\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DsVG1OSk5cnC","executionInfo":{"status":"ok","timestamp":1690292988098,"user_tz":-330,"elapsed":654,"user":{"displayName":"Don C John","userId":"06394153183726699086"}},"outputId":"ee92847a-cc72-4e92-c815-c6ae44b8d25a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Legitimate URL\n"]}]}]}