{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMiI+VYpLln9t7rpN0neuS/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0NO3Mz5cVXuJ","executionInfo":{"status":"ok","timestamp":1690396802585,"user_tz":-330,"elapsed":12136,"user":{"displayName":"Don C John","userId":"06394153183726699086"}},"outputId":"a16ed8e7-c649-436d-842b-e5a90831d344"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: python-whois in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from python-whois) (0.18.3)\n"]}],"source":["# Installing Packages\n","!pip install python-whois\n","!pip install -q streamlit"]},{"cell_type":"code","source":["%%writefile app.py\n","#Importing Packages\n","import pandas as pd\n","import re\n","import ipaddress\n","from urllib.parse import urlparse\n","import whois\n","import requests\n","from datetime import datetime\n","import streamlit as st\n","import pickle\n","\n","#Printing Title\n","st.title(\"URL Phishing Checker\")\n","\n","#Function to extract features from a URL\n","def extract_features_from_url(url):\n","    # Helper function to get the domain from a URL\n","    def get_domain(url):\n","        domain = urlparse(url).netloc\n","        if re.match(r\"^www.\", domain):\n","            domain = domain.replace(\"www.\", \"\")\n","        return domain\n","\n","    # Helper function to check for the presence of an IP address in the URL\n","    def having_ip(url):\n","        try:\n","            ipaddress.ip_address(url)\n","            ip = 1\n","        except:\n","            ip = 0\n","        return ip\n","\n","    # Helper function to check for the presence of '@' symbol in the URL\n","    def have_at_sign(url):\n","        if \"@\" in url:\n","            at = 1\n","        else:\n","            at = 0\n","        return at\n","\n","    # Helper function to compute the length of the URL\n","    def get_length(url):\n","        if len(url) < 54:\n","            length = 0\n","        else:\n","            length = 1\n","        return length\n","\n","    # Helper function to compute the depth of the URL\n","    def get_depth(url):\n","        s = urlparse(url).path.split('/')\n","        depth = 0\n","        for j in range(len(s)):\n","            if len(s[j]) != 0:\n","                depth = depth + 1\n","        return depth\n","\n","    # Helper function to check for the presence of \"//\" in the URL\n","    def redirection(url):\n","        pos = url.rfind('//')\n","        if pos > 6:\n","            if pos > 7:\n","                return 1\n","            else:\n","                return 0\n","        else:\n","            return 0\n","\n","    # Helper function to check for the presence of \"http/https\" in the domain part of the URL\n","    def http_domain(url):\n","        domain = urlparse(url).netloc\n","        if 'https' in domain:\n","            return 1\n","        else:\n","            return 0\n","\n","    # Helper function to check for the use of URL shortening services\n","    def tiny_url(url):\n","        shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n","                              r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n","                              r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n","                              r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n","                              r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n","                              r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n","                              r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n","                              r\"tr\\.im|link\\.zip\\.net\"\n","        match = re.search(shortening_services, url)\n","        if match:\n","            return 1\n","        else:\n","            return 0\n","\n","    # Helper function to check for the presence of '-' in the domain part of the URL\n","    def prefix_suffix(url):\n","        if '-' in urlparse(url).netloc:\n","            return 1  # phishing\n","        else:\n","            return 0  # legitimate\n","\n","    # Helper function to check for the availability of DNS records for the hostname\n","    def dns_record(domain_name):\n","        try:\n","            domain_info = whois.whois(domain_name)\n","            return 0\n","        except:\n","            return 1\n","\n","    # Helper function to check the web traffic of the URL\n","    def web_traffic(url):\n","        return 1  # Placeholder, you may implement the actual logic using web traffic data sources\n","\n","    # Helper function to compute the age of the domain\n","    def domain_age(domain_name):\n","        try:\n","            domain_info = whois.whois(domain_name)\n","            creation_date = domain_info.creation_date\n","            expiration_date = domain_info.expiration_date\n","            if (isinstance(creation_date, str) or isinstance(expiration_date, str)):\n","                try:\n","                    creation_date = datetime.strptime(str(creation_date), '%Y-%m-%d %H:%M:%S')\n","                    expiration_date = datetime.strptime(str(expiration_date), '%Y-%m-%d %H:%M:%S')\n","                except:\n","                    return 1\n","            if ((expiration_date is None) or (creation_date is None)):\n","                return 1\n","            elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n","                return 1\n","            else:\n","                age_of_domain = abs((expiration_date - creation_date).days)\n","                if ((age_of_domain / 30) < 6):\n","                    age = 1\n","                else:\n","                    age = 0\n","            return age\n","        except:\n","            return 1\n","\n","    # Helper function to compute the remaining domain time before expiration\n","    def domain_end(domain_name):\n","        try:\n","            domain_info = whois.whois(domain_name)\n","            expiration_date = domain_info.expiration_date\n","            if isinstance(expiration_date, str):\n","                try:\n","                    expiration_date = datetime.strptime(str(expiration_date), '%Y-%m-%d %H:%M:%S')\n","                except:\n","                    return 1\n","            if (expiration_date is None):\n","                return 1\n","            elif (type(expiration_date) is list):\n","                return 1\n","            else:\n","                today = datetime.now()\n","                end = abs((expiration_date - today).days)\n","                if ((end / 30) < 6):\n","                    end = 0\n","                else:\n","                    end = 1\n","            return end\n","        except:\n","            return 1\n","\n","    # Helper function to check for the presence of \"iframe\" tags in the webpage source code\n","    def iframe(response):\n","        if response == \"\":\n","            return 1\n","        else:\n","            if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n","                return 0\n","            else:\n","                return 1\n","\n","    # Helper function to check the effect of mouse over on the status bar\n","    def mouse_over(response):\n","        if response == \"\":\n","            return 1\n","        else:\n","            if re.findall(\"<script>.+onmouseover.+</script>\", response.text):\n","                return 1\n","            else:\n","                return 0\n","\n","    # Helper function to check the status of the right-click attribute\n","    def right_click(response):\n","        if response == \"\":\n","            return 1\n","        else:\n","            if re.findall(r\"event.button ?== ?2\", response.text):\n","                return 0\n","            else:\n","                return 1\n","\n","    # Helper function to check the number of forwardings in the URL\n","    def web_forwards(url):\n","        try:\n","            response = requests.get(url)\n","            if response.status_code == 200:\n","                return 0\n","            else:\n","                return 1\n","        except:\n","            return 1\n","\n","    # Extract features\n","    ip_present = having_ip(url)\n","    at_present = have_at_sign(url)\n","    url_len = get_length(url)\n","    url_depth = get_depth(url)\n","    redirection_present = redirection(url)\n","    https_in_domain = http_domain(url)\n","    tinyurl_present = tiny_url(url)\n","    prefix_suffix_present = prefix_suffix(url)\n","    dns_rec = dns_record(get_domain(url))\n","    web_traffic_status = web_traffic(url)\n","    domain_age_status = domain_age(get_domain(url))\n","    domain_end_status = domain_end(get_domain(url))\n","\n","    # As web_forwards function requires an actual request to the URL, we'll handle it separately\n","    try:\n","        response = requests.get(url)\n","        web_forwards_status = web_forwards(url)\n","    except:\n","        web_forwards_status = 1\n","\n","    # Create an array of the extracted features\n","    features_array = [ip_present, at_present, url_len, url_depth, redirection_present, https_in_domain, tinyurl_present,\n","                      prefix_suffix_present, dns_rec, web_traffic_status, domain_age_status, domain_end_status,\n","                      iframe(response), mouse_over(response), right_click(response), web_forwards_status]\n","\n","    return features_array\n","\n","# Load the XGBoost model\n","loaded_model = pickle.load(open(\"XGBoostClassifier.pickle.dat\", \"rb\"))\n","\n","#UI to input URL\n","url = st.text_input(\"Enter the URL to check\")\n","if url:\n","    #Extract Features from URL\n","    test_url = \"https://colab.research.google.com/drive/129-DGfnDTW08yCKcTrpyK5XYWpzCoMO3\"\n","    features = extract_features_from_url(url)\n","\n","    # Convert the preprocessed URL data to a DataFrame (assuming it's in the same format as the training data)\n","    feature_names = [\n","        'Have_IP', 'Have_At', 'URL_Length', 'URL_Depth', 'Redirection', 'https_Domain', 'TinyURL', 'Prefix/Suffix',\n","        'DNS_Record', 'Web_Traffic', 'Domain_Age', 'Domain_End', 'iFrame', 'Mouse_Over', 'Right_Click', 'Web_Forwards'\n","    ]\n","    url_df = pd.DataFrame([features], columns=feature_names)\n","\n","    # Predict the label using the loaded XGBoost model\n","    prediction = loaded_model.predict(url_df)\n","\n","    # Print the prediction (1 for phishing, 0 for legitimate)\n","    if prediction[0] == 1:\n","        st.error('Phishing URL', icon=\"🚨\")\n","    else:\n","        st.success('Legitimate URL', icon=\"✅\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5ay7qb3VnBn","executionInfo":{"status":"ok","timestamp":1690396802588,"user_tz":-330,"elapsed":17,"user":{"displayName":"Don C John","userId":"06394153183726699086"}},"outputId":"7e4a6f4c-28f6-4e69-a10d-0503a37fcaa7"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":["#Install localtunnel package for port exposing\n","!npm install localtunnel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RvbXQFs7Vs0I","executionInfo":{"status":"ok","timestamp":1690396803708,"user_tz":-330,"elapsed":1132,"user":{"displayName":"Don C John","userId":"06394153183726699086"}},"outputId":"532514af-097b-4ffb-8440-e752515d57c4"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n","\u001b[0m\n","+ localtunnel@2.0.2\n","updated 1 package and audited 36 packages in 0.786s\n","\n","3 packages are looking for funding\n","  run `npm fund` for details\n","\n","found \u001b[92m0\u001b[0m vulnerabilities\n","\n","\u001b[K\u001b[?25h"]}]},{"cell_type":"code","source":["!streamlit run /content/app.py &>/content/logs.txt &"],"metadata":{"id":"egCSyxESV1SQ","executionInfo":{"status":"ok","timestamp":1690396803708,"user_tz":-330,"elapsed":2,"user":{"displayName":"Don C John","userId":"06394153183726699086"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["!npx localtunnel --port 8501"],"metadata":{"id":"XTGAizLhOIgC","outputId":"dd14d0e5-4eaa-4215-af05-6d9f3b54eff0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690397339961,"user_tz":-330,"elapsed":536255,"user":{"displayName":"Don C John","userId":"06394153183726699086"}}},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25hnpx: installed 22 in 3.719s\n","your url is: https://free-books-switch.loca.lt\n","^C\n"]}]},{"cell_type":"markdown","source":["After Running the code kindly open the log.txt file and collect the External URL and provide if asked viewing the site"],"metadata":{"id":"y_M-OblJb93l"}}]}